# Environment settings
save_sst_embed: True
# pretrain_model_file_path: 'saved/saved_FairGo_PMF/FairGo_PMF-ml-1M-pretrain.pth'

# Data settings
LABEL_FIELD: label
threshold: {'rating': 3.0}
sst_attr_list: ['gender']
load_pretrain_weight: False
load_col:
  inter: [user_id,item_id,rating,timestamp]
  user: [user_id,gender]
#   user_emb: [uid,user_emb]
#   item_emb: [iid,item_emb]
# preload_weight: {'uid': user_emb, 'iid':item_emb}
# additional_feat_suffix: [user_emb,item_emb]
# alias_of_user_id: [uid]
# alias_of_item_id: [iid]

# model config
model: FairGo_PMF
aggr_method: 'LBA'
vs_weights: [4,1]
embedding_size: 64
dis_hidden_size_list: [16,8,4]
filter_hidden_size_list: [128,64]
activation: leakyrelu
fair_weight: 0.1

# training settings
pretrain_epochs: 600
train_epoch_interval: 5
weight_decay: 0.0001

# evalution settings
eval_args:
  split: {'RS':[8,1,1]}
  group_by: user
  order: RO
  mode: uni100
metrics: ["NDCG","Recall","Hit","MRR","DifferentialFairness","GiniIndex","PopularityPercentage",
        "ValueUnfairness","AbsoluteUnfairness","UnderUnfairness","OverUnfairness","NonParityUnfairness"]
valid_metric: NDCG@5
topk: [5]
popularity_ratio: 0.1
eval_batch_size: 16384
loss_decimal_place: 4
metric_decimal_place: 4